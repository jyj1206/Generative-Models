task: diffusion

model:
  type: ddpm
  img_size: 128          
  in_channels: 3
  num_res_blocks: 2      
  dim: 128                 
  
  dim_mults: [1, 2, 4, 8]
  
  attn_layers: [16]
  
  dropout: 0.0

dataset:
  name: custom
  root: ./data/celeba_hq_256

train:
  epochs: 500              
  batch_size: 8           
  num_workers: 4
  learning_rate: 0.00002   
  loss_fn: mse
  optimizer: adam
  ema: true
  ema_decay: 0.9999

diffusion:
  num_timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02
  variance_type: fixed_small